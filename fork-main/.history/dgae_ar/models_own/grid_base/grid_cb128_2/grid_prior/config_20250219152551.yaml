data:
  value:
    add_cycles_feat: true
    add_path_feat: true
    add_random_feat: true
    add_spectral_feat: true
    batch_size: 8
    data: grid
    dir: ./data
    max_feat_num: 0
    max_node_num: 342
    min_node_num: 12
    test_split: 0.2
dataset:
  value: grid
device:
  value: cuda:1
exp_name:
  value: grid_base
gpu:
  value: '1'
log:
  value:
    debug: false
    n_loggin_epochs: 100
    n_loggin_steps: 1000
    wandb: online
model:
  value:
    decoder:
      mlp_hidden_size: 128
      mlp_n_layers: 3
      n_layers: 6
      name: GNN
      nhf: 32
      normalization: batch_norm
      skip_connection: true
    encoder:
      mlp_hidden_size: 128
      mlp_n_layers: 3
      n_layers: 6
      name: GNN_PYG
      nhf: 32
      normalization: batch_norm
      skip_connection: true
    gamma: 0.1
    quantizer:
      codebook_size: 128
      commitment_cost: 0.25
      decay: 0.99
      epsilon: 1e-05
      init_steps: 0
      name: Quantizer
      nc: 2
      nz: 8
model_folder:
  value: ./wandb/enzymes_prior/files/config.yaml
run_name:
  value: grid_cb128_2
sample:
  value: false
train_autoencoder_skip:
  value: false
train_prior:
  value: true
training:
  value:
    batch_size: 16
    beta1: 0.9
    beta2: 0.999
    betas: !!python/tuple
    - 0.9
    - 0.999
    decay_iteration: 5000
    # epochs: 8000
    epochs: 16000 #todo
    learning_rate: 1.0e-05
    lr_decay: 0.5
    n_iter: 1000000
    sort_codebook: false
    sort_indices: true
transformer:
  value:
    d_model: 512
    n_blocks: 6
    num_heads: 16
work_type:
  value: train_prior
resume_from:
  value: "./models_own/grid_base/grid_cb128_2/grid_prior/checkpoint.pth"

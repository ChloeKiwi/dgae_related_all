_wandb:
    value:
        cli_version: 0.19.1
        m: []
        python_version: 3.8.20
        t:
            "1":
                - 1
                - 5
                - 53
                - 55
                - 77
            "2":
                - 1
                - 5
                - 53
                - 55
                - 77
            "3":
                - 3
                - 13
                - 14
                - 16
                - 23
                - 55
                - 61
            "4": 3.8.20
            "5": 0.19.1
            "8":
                - 5
            "12": 0.19.1
            "13": linux-x86_64
data:
    value:
        add_cycles_feat: true
        add_path_feat: true
        add_random_feat: true
        add_spectral_feat: true
        data: ENZYMES
        dir: ./data
        max_feat_num: 0
        max_node_num: 125
        min_node_num: 10
        test_split: 0.2
dataset:
    value: enzymes
exp_name:
    value: baseline-cb16_2
gpu:
    value: "3"
log:
    value:
        debug: false
        n_loggin_epochs: 1
        n_loggin_steps: 100
        wandb: online
model:
    value:
        decoder:
            mlp_hidden_size: 128
            mlp_n_layers: 3
            n_layers: 6
            name: GNN
            nhf: 32
            normalization: batch_norm
            skip_connection: true
        encoder:
            mlp_hidden_size: 128
            mlp_n_layers: 3
            n_layers: 6
            name: GNN_PYG
            nhf: 32
            normalization: batch_norm
            skip_connection: true
        gamma: 0.1
        quantizer:
            codebook_size: 32
            commitment_cost: 0.25
            decay: 0.99
            epsilon: 1e-05
            init_steps: 100
            name: Quantizer
            nc: 2
            nz: 8
model_folder:
    value: ./wandb/enzymes_prior/files/config.yaml
sample:
    value: false
train_prior:
    value: false
training:
    value:
        batch_size: 16
        beta1: 0.9
        beta2: 0.99
        betas:
            - 0.9
            - 0.99
        decay_iteration: 10000
        epochs: 10000
        learning_rate: 0.0005
        log: false
        lr_decay: 0.5
        n_iter: 100000
work_type:
    value: train_autoencoder
